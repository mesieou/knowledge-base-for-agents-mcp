# Knowledge Base MCP - Project Structure

## ğŸ“ Project Organization

```
knowledge-base-mcp/
â”œâ”€â”€ ğŸš€ server.py                    # Main MCP server
â”œâ”€â”€ ğŸ§ª test_load_documents.py       # Integration tests
â”œâ”€â”€ ğŸ“‹ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“– README_LOAD_DOCUMENTS.md     # Documentation
â”œâ”€â”€ ğŸ³ Dockerfile                   # Container setup
â”œâ”€â”€ ğŸ³ docker-compose.yml           # Multi-container setup
â”œâ”€â”€ ğŸš‚ railway.toml                 # Railway deployment config
â”‚
â”œâ”€â”€ ğŸ”§ tools/                       # MCP Tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ loadDocuments.py            # Main orchestrator tool
â”‚
â”œâ”€â”€ ğŸ“„ docling/                     # Document processing pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extraction.py               # Document extraction
â”‚   â”œâ”€â”€ chunking.py                 # Text chunking
â”‚   â””â”€â”€ embedding.py                # Embeddings & storage
â”‚
â””â”€â”€ ğŸ› ï¸ utils/                       # Shared utilities
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ tokenizer.py                # OpenAI tokenizer wrapper
    â””â”€â”€ sitemap.py                  # Sitemap parsing
```

## ğŸ”„ Data Flow

```
Sources â†’ Extract â†’ Chunk â†’ Embed â†’ Store
   â†“         â†“        â†“       â†“       â†“
[URLs]  [Documents] [Chunks] [Vectors] [Supabase]
```

## ğŸ“¦ Module Responsibilities

### ğŸš€ **server.py**
- MCP server setup and configuration
- Tool registration and routing
- Docker/Railway deployment ready

### ğŸ”§ **tools/loadDocuments.py**
- Thin orchestrator that coordinates the pipeline
- Environment variable handling
- Error management and reporting

### ğŸ“„ **docling/ package**
- **extraction.py**: Document conversion using docling
- **chunking.py**: Text chunking with HybridChunker
- **embedding.py**: OpenAI embeddings + PostgreSQL storage

### ğŸ› ï¸ **utils/ package**
- **tokenizer.py**: OpenAI-compatible tokenizer for chunking
- **sitemap.py**: Website sitemap parsing utilities

## ğŸ”Œ Import Structure

```python
# Clean imports
from tools import load_documents
from docling import extract_documents, chunk_documents
from utils import OpenAITokenizerWrapper
```

## ğŸ§ª Testing

```bash
# Test individual components
python docling/extraction.py
python docling/chunking.py
python docling/embedding.py

# Test full pipeline
python tools/loadDocuments.py

# Test MCP integration
python test_load_documents.py
```

## ğŸš€ Deployment

```bash
# Local development
python server.py

# Docker
docker-compose up

# Railway
railway up
```

This structure follows Python best practices with clear separation of concerns and modular design.
